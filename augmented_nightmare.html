<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Augmented Nightmare</title>
    <!-- Load Tailwind CSS for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Custom styles for the horror theme */
        body {
            background-color: #0d0d0d;
            font-family: 'Inter', sans-serif;
            color: #d1d5db; /* Light gray text */
            overflow: hidden; /* Prevent scrolling */
        }
        /* The video element is hidden, only used to feed the canvas */
        #video-feed {
            display: none;
        }
        /* Canvas for drawing the processed video feed and applying filters */
        #ar-canvas {
            /* Glitch/Horror effect styling */
            filter: grayscale(100%) contrast(150%);
            border: 4px solid #cc3333; /* Sinister border */
            box-shadow: 0 0 20px rgba(204, 51, 51, 0.7); /* Red glow */
            cursor: pointer;
        }
        .glitch-text {
            font-family: monospace;
            text-shadow: 1px 1px 0 #cc3333, -1px -1px 0 #33cccc;
            transition: opacity 0.3s ease-in-out;
            animation: flicker 0.15s infinite alternate;
        }
        @keyframes flicker {
            0% { opacity: 0.98; }
            50% { opacity: 0.9; }
            100% { opacity: 1; }
        }
    </style>
</head>
<body class="min-h-screen flex flex-col items-center justify-center p-4">

    <!-- Main Application Container -->
    <div id="app" class="w-full max-w-xl flex flex-col items-center space-y-4">

        <h1 class="text-3xl font-bold text-red-500 glitch-text text-center">
            [ Signal Scanner ]
        </h1>

        <!-- Video and Canvas Container -->
        <div class="relative w-full aspect-[4/3] rounded-lg overflow-hidden shadow-2xl">
            <!-- Hidden Video Stream Source -->
            <video id="video-feed" playsinline autoplay muted></video>
            <!-- Canvas where the processed feed and clues are drawn -->
            <canvas id="ar-canvas" class="w-full h-full rounded-lg transition-all duration-300"></canvas>
            
            <!-- Message Overlay -->
            <div id="message-box" class="absolute inset-0 bg-gray-900 bg-opacity-90 flex items-center justify-center p-4 text-center rounded-lg transition-opacity duration-500">
                <p id="message-text" class="text-xl font-mono text-red-400">
                    Initializing scanner... Grant camera access to begin the hunt.
                </p>
            </div>
        </div>
        
        <!-- Controls and Status -->
        <p id="status" class="text-sm font-mono text-gray-500">Status: Awaiting connection.</p>

        <!-- LLM Feature 1: Clue Generation Control -->
        <div class="flex flex-col items-center space-y-2 w-full">
            <button id="generate-clue-button" 
                    class="bg-gray-700 hover:bg-gray-600 text-white font-bold py-2 px-6 rounded-full shadow-md transition duration-150 transform hover:scale-105 active:scale-95 disabled:bg-gray-800 disabled:opacity-50"
                    disabled>
                Generate Next Mystery Clue âœ¨
            </button>
            <div id="clue-loading" class="text-sm font-mono text-red-400 hidden animate-pulse">
                Generating cryptic signal...
            </div>
        </div>

        <button id="scan-button" 
                class="bg-red-700 hover:bg-red-800 text-white font-bold py-3 px-8 rounded-full shadow-lg transition duration-150 transform hover:scale-105 active:scale-95 disabled:bg-gray-600 disabled:shadow-none"
                disabled>
            SCAN FOR CLUES
        </button>
        
        <p class="text-xs text-gray-700 text-center mt-2">
            Tap the scan button when you think you've found the location.
        </p>

    </div>

    <script>
        const video = document.getElementById('video-feed');
        const canvas = document.getElementById('ar-canvas');
        const ctx = canvas.getContext('2d');
        const statusEl = document.getElementById('status');
        const scanButton = document.getElementById('scan-button');
        const messageBox = document.getElementById('message-box');
        const messageText = document.getElementById('message-text');
        const generateClueButton = document.getElementById('generate-clue-button');
        const clueLoadingEl = document.getElementById('clue-loading');

        // Global API Configuration (Must be included)
        const apiKey = "";
        const textApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-09-2025:generateContent?key=${apiKey}`;
        const ttsApiUrl = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent?key=${apiKey}`;

        let stream = null;
        let isClueMode = false;
        let clueTimer = null;
        let currentClue = "INIT: THE PATH IS GUARDED BY THE OLDEST CLOCK."; 
        let currentWarning = "A signal is detected. Proceed with extreme caution.";

        // --- LLM Utility Functions ---

        // Utility for converting base64 to ArrayBuffer (for TTS)
        function base64ToArrayBuffer(base64) {
            const binaryString = atob(base64);
            const len = binaryString.length;
            const bytes = new Uint8Array(len);
            for (let i = 0; i < len; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }

        // Utility for converting PCM audio data to WAV format (for TTS)
        function pcmToWav(pcmData, sampleRate) {
            const numChannels = 1;
            const bitsPerSample = 16;
            const byteRate = sampleRate * numChannels * (bitsPerSample / 8);
            const blockAlign = numChannels * (bitsPerSample / 8);
            
            const wavLength = 44 + pcmData.byteLength;
            const buffer = new ArrayBuffer(wavLength);
            const view = new DataView(buffer);
            
            let offset = 0;
            
            // RIFF identifier
            view.setUint32(offset, 0x52494646, false); offset += 4;
            // file length
            view.setUint32(offset, wavLength - 8, true); offset += 4;
            // RIFF type
            view.setUint32(offset, 0x57415645, false); offset += 4;
            
            // format chunk identifier
            view.setUint32(offset, 0x666d7420, false); offset += 4;
            // format chunk length
            view.setUint32(offset, 16, true); offset += 4;
            // sample format (1 = PCM)
            view.setUint16(offset, 1, true); offset += 2;
            // number of channels
            view.setUint16(offset, numChannels, true); offset += 2;
            // sample rate
            view.setUint32(offset, sampleRate, true); offset += 4;
            // byte rate
            view.setUint32(offset, byteRate, true); offset += 4;
            // block align
            view.setUint16(offset, blockAlign, true); offset += 2;
            // bits per sample
            view.setUint16(offset, bitsPerSample, true); offset += 2;
            
            // data chunk identifier
            view.setUint32(offset, 0x64617461, false); offset += 4;
            // data chunk length
            view.setUint32(offset, pcmData.byteLength, true); offset += 4;
            
            // Write PCM data
            const pcmView = new Int16Array(pcmData.buffer);
            for (let i = 0; i < pcmView.length; i++) {
                view.setInt16(offset, pcmView[i], true);
                offset += 2;
            }
            
            return new Blob([buffer], { type: 'audio/wav' });
        }

        // Exponential Backoff Fetch Wrapper
        async function fetchWithBackoff(url, options) {
            const maxRetries = 5;
            let delay = 1000;
            
            for (let i = 0; i < maxRetries; i++) {
                try {
                    const response = await fetch(url, options);
                    if (!response.ok) {
                        if (response.status === 429 && i < maxRetries - 1) {
                            console.warn(`Rate limit exceeded (429). Retrying in ${delay / 1000}s...`);
                            await new Promise(resolve => setTimeout(resolve, delay));
                            delay *= 2; // Exponential backoff
                            continue; // Retry request
                        }
                        throw new Error(`API request failed with status: ${response.status} ${response.statusText}`);
                    }
                    return response;
                } catch (error) {
                    if (i === maxRetries - 1) {
                        console.error("API call failed after max retries:", error);
                        throw error;
                    }
                    // For network errors, wait and retry
                    console.warn(`Network error. Retrying in ${delay / 1000}s...`);
                    await new Promise(resolve => setTimeout(resolve, delay));
                    delay *= 2;
                }
            }
        }

        // --- Camera Setup ---

        // Function to handle retries for camera access with exponential backoff
        async function setupCamera() {
            messageText.textContent = 'Requesting camera permissions...';
            const maxRetries = 5;
            let delay = 1000;

            for (let i = 0; i < maxRetries; i++) {
                try {
                    // Request user-facing camera if available
                    stream = await navigator.mediaDevices.getUserMedia({ 
                        video: { facingMode: 'environment' } 
                    });
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        video.play();
                        // Set canvas dimensions to match video stream
                        canvas.width = video.videoWidth;
                        canvas.height = video.videoHeight;
                        messageBox.style.opacity = '0';
                        setTimeout(() => messageBox.style.display = 'none', 500);
                        statusEl.textContent = 'Status: Active Feed. Standby.';
                        scanButton.disabled = false;
                        generateClueButton.disabled = false; // Enable LLM feature
                        gameLoop(); // Start the main loop
                    };
                    return; // Success, exit function
                } catch (err) {
                    console.error(`Camera access attempt ${i + 1} failed:`, err);
                    if (i === maxRetries - 1) {
                        messageText.textContent = 'ERROR: Could not access camera. Ensure permissions are granted.';
                        statusEl.textContent = 'Status: ERROR';
                        return; // Failed after all retries
                    }
                    messageText.textContent = `Camera access failed. Retrying in ${delay / 1000}s...`;
                    await new Promise(resolve => setTimeout(resolve, delay));
                    delay *= 2; // Exponential backoff
                }
            }
        }

        function stopCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            statusEl.textContent = 'Status: Disconnected.';
            scanButton.disabled = true;
            generateClueButton.disabled = true;
        }

        // --- Core Game Loop ---
        function gameLoop() {
            if (!video.videoWidth) {
                requestAnimationFrame(gameLoop);
                return;
            }

            // 1. Draw the video frame onto the canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // 2. Apply Glitch Effect (Simulated via image data manipulation)
            if (!isClueMode) {
                const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                const data = imageData.data;
                for (let i = 0; i < data.length; i += 4) {
                    // Small random noise (darker pixels for grain)
                    if (Math.random() < 0.01) { 
                        data[i] = Math.max(0, data[i] - 50); 
                        data[i + 1] = Math.max(0, data[i + 1] - 50); 
                        data[i + 2] = Math.max(0, data[i + 2] - 50); 
                    }
                }
                ctx.putImageData(imageData, 0, 0);
            }
            
            // 3. Draw Clue Overlay if in Clue Mode
            if (isClueMode) {
                // Enhance the spooky filter dynamically in Clue Mode
                canvas.style.filter = 'grayscale(100%) contrast(300%) hue-rotate(180deg)'; // Hyper-distorted
                
                // Draw the Hidden Clue Text (now dynamic)
                ctx.fillStyle = 'rgba(255, 0, 0, 0.9)'; // Bright Red Clue
                ctx.shadowColor = 'red';
                ctx.shadowBlur = 10;
                ctx.font = 'bold 32px monospace'; // Slightly smaller font for long clues
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                
                // Use the dynamically generated clue text
                const clueText = currentClue;
                
                // Handle wrapping for long clues
                const words = clueText.split(' ');
                const maxWidth = canvas.width * 0.8;
                let line = '';
                const lines = [];
                
                // Simple text wrapping logic
                for (let n = 0; n < words.length; n++) {
                    const testLine = line + words[n] + ' ';
                    const metrics = ctx.measureText(testLine);
                    const testWidth = metrics.width;
                    if (testWidth > maxWidth && n > 0) {
                        lines.push(line);
                        line = words[n] + ' ';
                    } else {
                        line = testLine;
                    }
                }
                lines.push(line);

                const lineHeight = 40;
                let y = canvas.height / 2 - (lines.length / 2) * lineHeight;

                for (let i = 0; i < lines.length; i++) {
                    const offsetX = Math.random() * 10 - 5;
                    const offsetY = Math.random() * 10 - 5;
                    ctx.fillText(lines[i], canvas.width / 2 + offsetX, y + offsetY);
                    y += lineHeight;
                }
                
                // Draw a flashing border or indicator
                if (Math.random() < 0.5) {
                    ctx.strokeStyle = 'red';
                    ctx.lineWidth = 5;
                    ctx.strokeRect(20, 20, canvas.width - 40, canvas.height - 40);
                }

            } else {
                // Reset filter for normal view
                canvas.style.filter = 'grayscale(100%) contrast(150%)'; 
            }

            requestAnimationFrame(gameLoop);
        }

        // --- LLM Feature 1: Dynamic Clue Generation (Text) ---
        async function generateMysteryClue() {
            generateClueButton.disabled = true;
            scanButton.disabled = true;
            clueLoadingEl.classList.remove('hidden');
            
            // Possible themes/locations for a school ARG
            const themes = ["library archives", "old chemistry lab", "janitor's closet", "boiler room access", "empty auditorium", "behind the trophy case", "faculty lounge fridge"];
            const theme = themes[Math.floor(Math.random() * themes.length)];

            const systemPrompt = "You are an ancient, corrupted AI transmitting fragmented data. Generate a single, extremely cryptic and unsettling scavenger hunt clue (10-15 words max) related to a 'school ARG' and the theme provided. The clue must sound like a corrupted data transmission. Do not use the words 'clue' or 'theme'.";
            const userQuery = `Generate a cryptic message about the location: ${theme}`;

            const payload = {
                contents: [{ parts: [{ text: userQuery }] }],
                systemInstruction: { parts: [{ text: systemPrompt }] },
            };

            try {
                const response = await fetchWithBackoff(textApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(payload)
                });
                const result = await response.json();
                const generatedText = result?.candidates?.[0]?.content?.parts?.[0]?.text || "ERROR: SIGNAL LOST.";
                
                // Update both the visual clue and the audio warning text
                currentClue = generatedText.toUpperCase(); // Ensure uppercase for that scanner look
                currentWarning = `New signal detected. Origin point: ${theme}.`;
                
                statusEl.textContent = 'Status: New Clue Generated. Proceed with caution.';

            } catch (error) {
                console.error("Gemini Text API Error:", error);
                currentClue = "!!! SIGNAL CORRUPTION. TRY AGAIN. ERROR 404 !!!";
                currentWarning = "Signal corruption detected.";
                statusEl.textContent = 'Status: CLUE ERROR. Using fallback.';
            } finally {
                generateClueButton.disabled = false;
                scanButton.disabled = false;
                clueLoadingEl.classList.add('hidden');
            }
        }


        // --- LLM Feature 2: Audio Jumpscare/Warning (TTS) ---
        async function playTTSWarning() {
            const textToSpeak = currentWarning; 

            // Use a firm voice and request a whisper/eerie tone
            const ttsPayload = {
                contents: [{
                    parts: [{ text: `Say in a fast, low, heavily filtered, and slightly glitching whisper: ${textToSpeak}` }]
                }],
                generationConfig: {
                    responseModalities: ["AUDIO"],
                    speechConfig: {
                        voiceConfig: {
                            prebuiltVoiceConfig: { voiceName: "Kore" } 
                        }
                    }
                },
            };

            try {
                const response = await fetchWithBackoff(ttsApiUrl, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(ttsPayload)
                });
                const result = await response.json();
                
                const part = result?.candidates?.[0]?.content?.parts?.[0];
                const audioData = part?.inlineData?.data;
                const mimeType = part?.inlineData?.mimeType;

                if (audioData && mimeType && mimeType.startsWith("audio/")) {
                    const match = mimeType.match(/rate=(\d+)/);
                    const sampleRate = match ? parseInt(match[1], 10) : 24000;
                    
                    const pcmData = base64ToArrayBuffer(audioData);
                    const pcm16 = new Int16Array(pcmData);
                    
                    const wavBlob = pcmToWav(pcm16, sampleRate);
                    const audioUrl = URL.createObjectURL(wavBlob);
                    
                    const audio = new Audio(audioUrl);
                    audio.play().catch(e => console.error("Audio play failed:", e));

                } else {
                    console.warn("TTS API did not return valid audio data.");
                }
            } catch (error) {
                console.error("Gemini TTS API Error:", error);
            }
        }


        // --- Event Handlers ---

        function triggerClueMode() {
            if (isClueMode) return;
            
            // Play the TTS warning immediately
            playTTSWarning(); 
            
            isClueMode = true;
            scanButton.disabled = true;
            generateClueButton.disabled = true; // Disable LLM feature while scanning
            scanButton.textContent = 'SIGNAL DETECTED... WARNING!';
            statusEl.textContent = 'Status: CLUE ACTIVE! MEMORIZE!';

            // Clue is visible for 5 seconds
            clueTimer = setTimeout(() => {
                isClueMode = false;
                scanButton.disabled = false;
                generateClueButton.disabled = false; // Re-enable LLM feature
                scanButton.textContent = 'SCAN FOR CLUES';
                statusEl.textContent = 'Status: Active Feed. Standby.';
            }, 5000); // Clue lasts 5 seconds
        }

        scanButton.addEventListener('click', triggerClueMode);
        generateClueButton.addEventListener('click', generateMysteryClue);
        
        // --- Initialization ---
        window.onload = setupCamera;
        window.onbeforeunload = stopCamera;

    </script>
</body>
</html>
